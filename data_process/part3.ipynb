{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0204ea32-837c-4495-8866-7d3d540e61a6",
   "metadata": {},
   "source": [
    "# Generating and Merging Isochrone Areas for Railway Stations Using OpenRouteService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07518ec2-d341-4736-a608-3b9103aed3cd",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äì Batch Request and Export of Isochrone Areas from ORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b40fb1-5fab-4e79-ade9-be45217c90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openrouteservice\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Initialize ORS client\n",
    "client = openrouteservice.Client(key='xxx')  \n",
    "\n",
    "# Read station data\n",
    "df = pd.read_csv('railway_stations.csv')\n",
    "stations = df[['StationName', 'WGS84_Lng', 'WGS84_Lat']].dropna()\n",
    "\n",
    "# Output directory and log file paths\n",
    "output_folder = 'isochrones_geojson'\n",
    "log_success_path = 'success_log.txt'\n",
    "log_fail_path = 'fail_log.txt'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Track already processed files to avoid duplication\n",
    "done_files = set([f.split('_')[0] for f in os.listdir(output_folder) if f.endswith('.geojson')])\n",
    "\n",
    "# Limit the number of requests per run\n",
    "MAX_RUN = 300\n",
    "run_count = 0\n",
    "\n",
    "# Open log files in append mode\n",
    "with open(log_success_path, 'a', encoding='utf-8') as success_log, \\\n",
    "     open(log_fail_path, 'a', encoding='utf-8') as fail_log:\n",
    "\n",
    "    for _, row in stations.iterrows():\n",
    "        name = row['StationName']\n",
    "        lon, lat = row['WGS84_Lng'], row['WGS84_Lat']\n",
    "\n",
    "        if name in done_files:\n",
    "            print(f'Skipped (already processed): {name}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = client.isochrones(\n",
    "                locations=[[lon, lat]],\n",
    "                range=[3600],\n",
    "                range_type='time',\n",
    "                location_type='start',\n",
    "                smoothing=0.3\n",
    "            )\n",
    "\n",
    "            # Save as GeoJSON\n",
    "            out_path = os.path.join(output_folder, f'{name}_1hour.geojson')\n",
    "            with open(out_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result, f)\n",
    "\n",
    "            print(f'‚úÖ Success: {name}')\n",
    "            success_log.write(f'{name}\\n')\n",
    "            run_count += 1\n",
    "            time.sleep(2)\n",
    "\n",
    "            if run_count >= MAX_RUN:\n",
    "                print(f'üîö Max run limit reached ({MAX_RUN} records). Please continue tomorrow.')\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Failed: {name}, Error: {e}')\n",
    "            fail_log.write(f'{name},{e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c36f50-7eee-4842-a1fd-f4c07accaf3e",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äì Merging Individual Isochrone GeoJSON Files into a Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ddc52-d985-4f6c-8c79-62cf625dbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "geojson_folder = 'isochrones_geojson'\n",
    "geojson_files = [os.path.join(geojson_folder, f) for f in os.listdir(geojson_folder) if f.endswith('.geojson')]\n",
    "\n",
    "gdf_list = [gpd.read_file(f) for f in geojson_files]\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
    "merged_gdf.crs = 'EPSG:4326'\n",
    "\n",
    "merged_gdf.to_file('merged_isochrones.geojson', driver='GeoJSON')\n",
    "print('‚úÖ Merging completed. Output file: merged_isochrones.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6448de4-bd9c-4b05-bfa4-398e3a734eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9fbb916-160b-48ce-99c1-00d43ce41133",
   "metadata": {},
   "source": [
    "# Batch Retrieval and Coordinate Conversion of Long-Distance Bus Stations in Guangdong via AMap API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8bb6c-9cac-421c-a731-561e26817acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import math\n",
    "\n",
    "API_KEY = \"xxx\"  \n",
    "KEYWORD = \"ÈïøÈÄîÊ±ΩËΩ¶Á´ô\"\n",
    "CITY = \"Guangdong\"\n",
    "OUTPUT_FILE = \"guangdong_bus_stations.geojson\"\n",
    "\n",
    "# Check if coordinates are outside China\n",
    "def out_of_china(lon, lat):\n",
    "    return not (72.004 <= lon <= 137.8347 and 0.8293 <= lat <= 55.8271)\n",
    "\n",
    "# Latitude offset transformation\n",
    "def transform_lat(lon, lat):\n",
    "    ret = -100.0 + 2.0 * lon + 3.0 * lat + 0.2 * lat * lat + \\\n",
    "        0.1 * lon * lat + 0.2 * math.sqrt(abs(lon))\n",
    "    ret += (20.0 * math.sin(6.0 * lon * math.pi) + 20.0 *\n",
    "            math.sin(2.0 * lon * math.pi)) * 2.0 / 3.0\n",
    "    ret += (20.0 * math.sin(lat * math.pi) + 40.0 *\n",
    "            math.sin(lat / 3.0 * math.pi)) * 2.0 / 3.0\n",
    "    ret += (160.0 * math.sin(lat / 12.0 * math.pi) + 320 *\n",
    "            math.sin(lat * math.pi / 30.0)) * 2.0 / 3.0\n",
    "    return ret\n",
    "\n",
    "# Longitude offset transformation\n",
    "def transform_lon(lon, lat):\n",
    "    ret = 300.0 + lon + 2.0 * lat + 0.1 * lon * lon + \\\n",
    "        0.1 * lon * lat + 0.1 * math.sqrt(abs(lon))\n",
    "    ret += (20.0 * math.sin(6.0 * lon * math.pi) + 20.0 *\n",
    "            math.sin(2.0 * lon * math.pi)) * 2.0 / 3.0\n",
    "    ret += (20.0 * math.sin(lon * math.pi) + 40.0 *\n",
    "            math.sin(lon / 3.0 * math.pi)) * 2.0 / 3.0\n",
    "    ret += (150.0 * math.sin(lon / 12.0 * math.pi) + 300.0 *\n",
    "            math.sin(lon / 30.0 * math.pi)) * 2.0 / 3.0\n",
    "    return ret\n",
    "\n",
    "# Convert GCJ-02 to WGS-84\n",
    "def gcj02_to_wgs84(lon, lat):\n",
    "    if out_of_china(lon, lat):\n",
    "        return lon, lat\n",
    "    a = 6378245.0\n",
    "    ee = 0.006693421622965943\n",
    "    d_lat = transform_lat(lon - 105.0, lat - 35.0)\n",
    "    d_lon = transform_lon(lon - 105.0, lat - 35.0)\n",
    "    rad_lat = lat / 180.0 * math.pi\n",
    "    magic = math.sin(rad_lat)\n",
    "    magic = 1 - ee * magic * magic\n",
    "    sqrt_magic = math.sqrt(magic)\n",
    "    d_lat = (d_lat * 180.0) / ((a * (1 - ee)) / (magic * sqrt_magic) * math.pi)\n",
    "    d_lon = (d_lon * 180.0) / (a / sqrt_magic * math.cos(rad_lat) * math.pi)\n",
    "    return lon - d_lon, lat - d_lat\n",
    "\n",
    "# Request POIs from AMap API\n",
    "def fetch_poi(page=1):\n",
    "    url = \"https://restapi.amap.com/v3/place/text\"\n",
    "    params = {\n",
    "        \"key\": API_KEY,\n",
    "        \"keywords\": KEYWORD,\n",
    "        \"city\": CITY,\n",
    "        \"output\": \"JSON\",\n",
    "        \"offset\": 50,\n",
    "        \"page\": page,\n",
    "        \"extensions\": \"base\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    all_pois = []\n",
    "    for page in range(1, 101):  # Up to 100 pages\n",
    "        data = fetch_poi(page)\n",
    "        if data and data.get(\"pois\"):\n",
    "            pois = data[\"pois\"]\n",
    "            if not pois:\n",
    "                break\n",
    "            all_pois.extend(pois)\n",
    "            time.sleep(0.2)  # Avoid rate limiting\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Total number of long-distance bus stations retrieved: {len(all_pois)}\")\n",
    "\n",
    "    records = []\n",
    "    for poi in all_pois:\n",
    "        try:\n",
    "            lon_gcj, lat_gcj = map(float, poi[\"location\"].split(\",\"))\n",
    "            lon_wgs, lat_wgs = gcj02_to_wgs84(lon_gcj, lat_gcj)\n",
    "            records.append({\n",
    "                \"name\": poi.get(\"name\"),\n",
    "                \"address\": poi.get(\"address\"),\n",
    "                \"type\": poi.get(\"type\"),\n",
    "                \"gcj02_location\": poi.get(\"location\"),\n",
    "                \"geometry\": Point(lon_wgs, lat_wgs)\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(records, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    gdf.to_file(OUTPUT_FILE, driver=\"GeoJSON\")\n",
    "    print(f\"Exported to WGS84 GeoJSON file: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a3a14-1b06-4f5e-a59f-88d23aa73149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Read the imported GeoJSON file\n",
    "gdf = gpd.read_file(\"guangdong_bus_stations.geojson\")\n",
    "\n",
    "# Clean the 'address' field: ensure all values are strings to avoid map/null types\n",
    "def clean_address(val):\n",
    "    if isinstance(val, str):\n",
    "        return val\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Apply the cleaning function\n",
    "gdf[\"address\"] = gdf[\"address\"].apply(clean_address)\n",
    "\n",
    "# Export to a new GeoJSON file (cleaned data)\n",
    "gdf.to_file(\"guangdong_bus_stations_clean.geojson\", driver=\"GeoJSON\")\n",
    "print(\"Field cleaning completed. Exported to guangdong_bus_stations_clean.geojson.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6c28e-89f8-4e13-9567-47575f6b975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Read the cleaned GeoJSON file\n",
    "gdf = gpd.read_file(\"guangdong_bus_stations_clean.geojson\")\n",
    "\n",
    "# Export to Shapefile format (a set of .shp/.shx/.dbf/.prj files will be created)\n",
    "gdf.to_file(\"guangdong_bus_stations_clean.shp\", driver=\"ESRI Shapefile\")\n",
    "\n",
    "print(\"Exported to Shapefile format: guangdong_bus_stations_clean.shp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
